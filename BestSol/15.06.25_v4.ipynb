{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 12190436,
          "sourceType": "datasetVersion",
          "datasetId": 7678427
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Brief Description:\n",
        "\n",
        "In this Notebook, I tried to predict bus seats for the year 2025, January-February, given by Analytics Vidhya. By reading the problem statement, I get an idea about how to approach this problem, tried many ways like using normal machine learning techniques like random forest decision tree, and SVM, etc, but got very poor results then I started with Boosting algorithms like LightGBM, CatBoost, XgBoost, but still getting poor results then tried optuna for hyperparameter tuning by trying so many approaches it's clear to me that this real life data has many challenges either outliers, having different statistical distributions of different variables I also tried time series but whichever algorithm I tried to follow gave me bad validation RMSE of or bad overfitting results. Then I tried stacking algos, tried to club one or two algos, getting good results and improving Validation RMSE without overfitting. Then I got my best baseline algorithm (which is described in this solution), then tried different feature engineering, and added many derived features to improve my RMSE.\n",
        "\n",
        "Here's a brief description of my algorithm,\n",
        "This solution consists of a blended ensemble model for bus seat demand forecasting using LightGBM, XGBoost, and Ridge regression as a meta-learner. It starts by loading and preprocessing the train, test, and transactions datasets, focusing on `dbd == 15` records to reflect booking behavior 15 days before the journey. The merged data undergoes rich feature engineering, including temporal features (like day of week, month, weekend flags), demand metrics (like search-per-seat ratio), route-level aggregations (mean, median, frequency), and interaction features such as `search_x_weekend` and `route_dow_final_seatcount_skew`.\n",
        "\n",
        "Categorical variables are label-encoded, and several derived features like `is_same_region`, `route_tier_combo`, and `route_freq_rank` are created to capture region/tier dynamics and route popularity. After sorting chronologically, the last 15% of the data is held out for validation to preserve time-based integrity.\n",
        "\n",
        "The model is trained using LightGBM and XGBoost separately with tuned hyperparameters and early stopping. Predictions from both models on validation and test sets are combined into a second-level dataset, which is fed into a Ridge regression meta-model. The meta-model is trained on validation predictions and then used to generate final test predictions. The final blended validation RMSE is printed to evaluate ensemble performance. This approach captures diverse model behaviors and route-specific patterns to enhance prediction accuracy."
      ],
      "metadata": {
        "id": "TCP1czbdzvJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Required Libraries"
      ],
      "metadata": {
        "id": "aFx1zH-U0BMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-20T16:47:52.741406Z",
          "iopub.execute_input": "2025-06-20T16:47:52.741629Z",
          "iopub.status.idle": "2025-06-20T16:48:00.496789Z",
          "shell.execute_reply.started": "2025-06-20T16:47:52.741609Z",
          "shell.execute_reply": "2025-06-20T16:48:00.495783Z"
        },
        "id": "tWCS6MP8-gTj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "TyM9OZle0kqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loading\n",
        "train = pd.read_csv(\"/kaggle/input/redbus-dataset/train-zip/train/train.csv\", parse_dates=[\"doj\"])\n",
        "transactions = pd.read_csv(\"/kaggle/input/redbus-dataset/train-zip/train/transactions.csv\", parse_dates=[\"doj\", \"doi\"])\n",
        "test = pd.read_csv(\"/kaggle/input/redbus-dataset/test.csv\", parse_dates=[\"doj\"])\n",
        "\n",
        "transactions[\"doj\"] = pd.to_datetime(transactions[\"doj\"])\n",
        "transactions[\"doj_month\"] = transactions[\"doj\"].dt.month\n",
        "transactions[\"doj_dayofweek\"] = transactions[\"doj\"].dt.dayofweek\n",
        "transactions[\"route_id\"] = transactions[\"srcid\"] * 10000 + transactions[\"destid\"]\n",
        "transactions[\"search_per_seat\"] = transactions[\"cumsum_searchcount\"] / (transactions[\"cumsum_seatcount\"] + 1)\n",
        "\n",
        "# Merge Data\n",
        "db15 = transactions[transactions[\"dbd\"] == 15]\n",
        "train_merged = train.merge(db15, on=[\"doj\", \"srcid\", \"destid\"], how=\"left\")\n",
        "test_merged = test.merge(db15, on=[\"doj\", \"srcid\", \"destid\"], how=\"left\")\n",
        "\n",
        "# Feature Engineering\n",
        "def add_features(df):\n",
        "    df[\"doj_dayofweek\"] = df[\"doj\"].dt.dayofweek\n",
        "    df[\"doj_month\"] = df[\"doj\"].dt.month\n",
        "    df[\"doj_day\"] = df[\"doj\"].dt.day\n",
        "    df[\"is_weekend\"] = df[\"doj_dayofweek\"].isin([5, 6]).astype(int)\n",
        "    df[\"search_per_seat\"] = df[\"cumsum_searchcount\"] / (df[\"cumsum_seatcount\"] + 1)\n",
        "    df[\"route_id\"] = df[\"srcid\"] * 10000 + df[\"destid\"]\n",
        "    return df\n",
        "\n",
        "train_merged = add_features(train_merged)\n",
        "test_merged = add_features(test_merged)\n",
        "\n",
        "route_stats = train_merged.groupby(\"route_id\")[\"final_seatcount\"].agg([\"mean\", \"count\", \"median\"]).reset_index()\n",
        "route_stats.columns = [\"route_id\", \"route_avg_seatcount\", \"route_freq\", \"route_median\"]\n",
        "train_merged = train_merged.merge(route_stats, on=\"route_id\", how=\"left\")\n",
        "test_merged = test_merged.merge(route_stats, on=\"route_id\", how=\"left\")\n",
        "\n",
        "train_merged[\"search_x_weekend\"] = train_merged[\"search_per_seat\"] * train_merged[\"is_weekend\"]\n",
        "test_merged[\"search_x_weekend\"] = test_merged[\"search_per_seat\"] * test_merged[\"is_weekend\"]\n",
        "\n",
        "train_merged[\"is_month_end\"] = train_merged[\"doj\"].dt.is_month_end.astype(int)\n",
        "test_merged[\"is_month_end\"] = test_merged[\"doj\"].dt.is_month_end.astype(int)\n",
        "train_merged[\"days_to_weekend\"] = 6 - train_merged[\"doj_dayofweek\"]\n",
        "test_merged[\"days_to_weekend\"] = 6 - test_merged[\"doj_dayofweek\"]\n",
        "\n",
        "train_merged[\"search_to_seat_ratio\"] = train_merged[\"cumsum_searchcount\"] / (train_merged[\"cumsum_seatcount\"] + 1)\n",
        "test_merged[\"search_to_seat_ratio\"] = test_merged[\"cumsum_searchcount\"] / (test_merged[\"cumsum_seatcount\"] + 1)\n",
        "\n",
        "train_merged[\"is_same_region\"] = (train_merged[\"srcid_region\"] == train_merged[\"destid_region\"]).astype(int)\n",
        "test_merged[\"is_same_region\"] = (test_merged[\"srcid_region\"] == test_merged[\"destid_region\"]).astype(int)\n",
        "\n",
        "cat_cols = [\"srcid_region\", \"destid_region\", \"srcid_tier\", \"destid_tier\"]\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    train_merged[col] = le.fit_transform(train_merged[col].astype(str))\n",
        "    test_merged[col] = le.transform(test_merged[col].astype(str))\n",
        "\n",
        "train_merged[\"route_tier_combo\"] = train_merged[\"srcid_tier\"] * 10 + train_merged[\"destid_tier\"]\n",
        "test_merged[\"route_tier_combo\"] = test_merged[\"srcid_tier\"] * 10 + test_merged[\"destid_tier\"]\n",
        "\n",
        "route_freq_rank = train_merged.groupby(\"route_id\")[\"final_seatcount\"].count().rank(method=\"min\", ascending=False).to_dict()\n",
        "train_merged[\"route_freq_rank\"] = train_merged[\"route_id\"].map(route_freq_rank)\n",
        "test_merged[\"route_freq_rank\"] = test_merged[\"route_id\"].map(route_freq_rank)\n",
        "\n",
        "# Feature Adding\n",
        "skew_feature = (\n",
        "    train_merged.groupby([\"route_id\", \"doj_dayofweek\"])[\"final_seatcount\"]\n",
        "    .skew()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"final_seatcount\": \"route_dow_final_seatcount_skew\"})\n",
        ")\n",
        "train_merged = train_merged.merge(skew_feature, on=[\"route_id\", \"doj_dayofweek\"], how=\"left\")\n",
        "test_merged = test_merged.merge(skew_feature, on=[\"route_id\", \"doj_dayofweek\"], how=\"left\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-20T16:48:04.414357Z",
          "iopub.execute_input": "2025-06-20T16:48:04.415305Z",
          "iopub.status.idle": "2025-06-20T16:48:10.768246Z",
          "shell.execute_reply.started": "2025-06-20T16:48:04.415269Z",
          "shell.execute_reply": "2025-06-20T16:48:10.767133Z"
        },
        "id": "GWw6kWhk-gTp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training and Prediction of Test Data"
      ],
      "metadata": {
        "id": "EYEBBvsG0qaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_merged = train_merged.sort_values(\"doj\")\n",
        "split_idx = int(len(train_merged) * 0.85)\n",
        "\n",
        "features = [\n",
        "    \"doj_dayofweek\", \"doj_month\", \"doj_day\", \"is_weekend\", \"cumsum_seatcount\", \"cumsum_searchcount\",\n",
        "    \"search_per_seat\", \"srcid_region\", \"destid_region\", \"srcid_tier\", \"destid_tier\", \"route_id\",\n",
        "    \"route_avg_seatcount\", \"route_freq\", \"search_x_weekend\", \"route_median\", \"is_month_end\",\n",
        "    \"days_to_weekend\", \"search_to_seat_ratio\", \"route_tier_combo\", \"is_same_region\",\n",
        "    \"route_freq_rank\", \"route_dow_final_seatcount_skew\"\n",
        "]\n",
        "\n",
        "X_train = train_merged.iloc[:split_idx][features]\n",
        "y_train = train_merged.iloc[:split_idx][\"final_seatcount\"]\n",
        "X_val = train_merged.iloc[split_idx:][features]\n",
        "y_val = train_merged.iloc[split_idx:][\"final_seatcount\"]\n",
        "X_test = test_merged[features]\n",
        "\n",
        "# Setting the parameters for base models\n",
        "params_lgb = {\n",
        "    \"objective\": \"regression\", \"metric\": \"rmse\", \"verbosity\": -1,\n",
        "    \"boosting_type\": \"gbdt\", \"learning_rate\": 0.03,\n",
        "    \"num_leaves\": 50, \"feature_fraction\": 0.9,\n",
        "    \"bagging_fraction\": 0.8, \"bagging_freq\": 5, \"seed\": 42\n",
        "}\n",
        "params_xgb = {\n",
        "    \"objective\": \"reg:squarederror\", \"eval_metric\": \"rmse\",\n",
        "    \"learning_rate\": 0.03, \"max_depth\": 7,\n",
        "    \"subsample\": 0.8, \"colsample_bytree\": 0.9, \"seed\": 42\n",
        "}\n",
        "\n",
        "# Base Model 1\n",
        "lgb_train = lgb.Dataset(X_train, y_train)\n",
        "lgb_val = lgb.Dataset(X_val, y_val)\n",
        "model_lgb = lgb.train(params_lgb, lgb_train, num_boost_round=2000, valid_sets=[lgb_val], callbacks=[lgb.early_stopping(50)])\n",
        "preds_lgb_val = model_lgb.predict(X_val)\n",
        "preds_lgb_test = model_lgb.predict(X_test)\n",
        "\n",
        "# Base Model 2\n",
        "model_xgb = xgb.XGBRegressor(**params_xgb, n_estimators=2000)\n",
        "model_xgb.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=50, verbose=False)\n",
        "preds_xgb_val = model_xgb.predict(X_val)\n",
        "preds_xgb_test = model_xgb.predict(X_test)\n",
        "\n",
        "# Meta-Model\n",
        "stk_train = pd.DataFrame({\"lgb\": preds_lgb_val, \"xgb\": preds_xgb_val})\n",
        "stk_test = pd.DataFrame({\"lgb\": preds_lgb_test, \"xgb\": preds_xgb_test})\n",
        "meta = Ridge(alpha=1.0)\n",
        "\n",
        "# Final Prediction on test data\n",
        "meta.fit(stk_train, y_val)\n",
        "meta_val_preds = meta.predict(stk_train) # this for checking validation set predictions\n",
        "meta_test_preds = meta.predict(stk_test)\n",
        "\n",
        "val_rmse = mean_squared_error(y_val, meta_val_preds, squared=False)\n",
        "print(\"Validation RMSE (Blended):\", val_rmse)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-20T16:48:13.886605Z",
          "iopub.execute_input": "2025-06-20T16:48:13.886927Z",
          "iopub.status.idle": "2025-06-20T16:48:20.762574Z",
          "shell.execute_reply.started": "2025-06-20T16:48:13.886902Z",
          "shell.execute_reply": "2025-06-20T16:48:20.761497Z"
        },
        "id": "cWrJ94rt-gTq",
        "outputId": "3419f778-6a78-4533-d61d-249ee4f508c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Training until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[356]\tvalid_0's rmse: 635.15\nValidation RMSE (Blended): 565.4098054288642\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submission File"
      ],
      "metadata": {
        "id": "1HjP5vzD092R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission = test[[\"route_key\"]].copy()\n",
        "submission[\"final_seatcount\"] = np.round(np.clip(meta_test_preds, 0, None)).astype(int)\n",
        "submission.to_csv(\"submission_skew.csv\", index=False)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-20T16:48:40.652685Z",
          "iopub.execute_input": "2025-06-20T16:48:40.653061Z",
          "iopub.status.idle": "2025-06-20T16:48:40.676240Z",
          "shell.execute_reply.started": "2025-06-20T16:48:40.653034Z",
          "shell.execute_reply": "2025-06-20T16:48:40.675064Z"
        },
        "id": "YNJOBDdo-gTs"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}