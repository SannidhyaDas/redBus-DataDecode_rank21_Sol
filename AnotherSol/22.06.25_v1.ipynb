{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12190436,"sourceType":"datasetVersion","datasetId":7678427},{"sourceId":12245926,"sourceType":"datasetVersion","datasetId":7715969}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ================== Imports ==================\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T11:07:39.004140Z","iopub.execute_input":"2025-06-22T11:07:39.005034Z","iopub.status.idle":"2025-06-22T11:07:39.009557Z","shell.execute_reply.started":"2025-06-22T11:07:39.005005Z","shell.execute_reply":"2025-06-22T11:07:39.008560Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# ================== Data Loading ==================\ntrain = pd.read_csv(\"/kaggle/input/redbus-dataset/train-zip/train/train.csv\", parse_dates=[\"doj\"])\ntransactions = pd.read_csv(\"/kaggle/input/redbus-dataset/train-zip/train/transactions.csv\", parse_dates=[\"doj\", \"doi\"])\ntest = pd.read_csv(\"/kaggle/input/redbus-dataset/test.csv\", parse_dates=[\"doj\"])\nholidays_df = pd.read_csv(\"/kaggle/input/holiday-23-25/holiday_dates.csv\")  # Has columns: start_date, end_date, holiday\n\n# ================== Holiday Preprocessing ==================\n# Define date parser to ensure correct conversion\ndate_parser = lambda x: pd.to_datetime(x, format='%m/%d/%Y', errors='coerce')\n\n# Apply date parser to 'Start' and 'End' columns\nholidays_df['Start'] = pd.to_datetime(holidays_df['Start'], format='%m/%d/%Y', errors='coerce')\nholidays_df['End'] = pd.to_datetime(holidays_df['End'], format='%m/%d/%Y', errors='coerce')\n\n# Remove rows with invalid dates\nholidays_df = holidays_df[(holidays_df['Start'].notna()) & (holidays_df['End'].notna())]\n\n# Initialize holiday ranges list\nholiday_ranges = []\n\n# Iterate over holiday dates and create date ranges\nfor _, row in holidays_df.iterrows():\n    start = row['Start']\n    end = row['End']\n    holiday_ranges.extend(pd.date_range(start, end).tolist())\n\n# Create holiday dates DataFrame\nholiday_dates = pd.DataFrame({\"date\": holiday_ranges})\n\n# Group by 'date' and count occurrences\nholiday_counts = holiday_dates.groupby(\"date\").size().reset_index(name=\"holiday_count\")\n\n# ================== Merge Data ==================\ntransactions[\"doj\"] = pd.to_datetime(transactions[\"doj\"])\ndb15 = transactions[transactions[\"dbd\"] == 15]\ntrain_merged = train.merge(db15, on=[\"doj\", \"srcid\", \"destid\"], how=\"left\")\ntest_merged = test.merge(db15, on=[\"doj\", \"srcid\", \"destid\"], how=\"left\")\n\n# ================== Feature Engineering ==================\ndef add_features(df):\n    df[\"doj_dayofweek\"] = df[\"doj\"].dt.dayofweek\n    df[\"doj_month\"] = df[\"doj\"].dt.month\n    df[\"doj_day\"] = df[\"doj\"].dt.day\n    df[\"is_weekend\"] = df[\"doj_dayofweek\"].isin([5, 6]).astype(int)\n    df[\"search_per_seat\"] = df[\"cumsum_searchcount\"] / (df[\"cumsum_seatcount\"] + 1)\n    df[\"route_id\"] = df[\"srcid\"] * 10000 + df[\"destid\"]\n    return df\n\ntrain_merged = add_features(train_merged)\ntest_merged = add_features(test_merged)\n\n# Add holiday features\nfor df in [train_merged, test_merged]:\n    df[\"doj_date\"] = pd.to_datetime(df[\"doj\"].dt.date)\n\ntrain_merged = train_merged.merge(holiday_counts, left_on=\"doj_date\", right_on=\"date\", how=\"left\")\ntest_merged = test_merged.merge(holiday_counts, left_on=\"doj_date\", right_on=\"date\", how=\"left\")\n\nfor df in [train_merged, test_merged]:\n    df[\"is_holiday\"] = df[\"holiday_count\"].notna().astype(int)\n    df[\"holiday_count\"] = df[\"holiday_count\"].fillna(0)\n    df.drop(columns=[\"doj_date\", \"date\"], inplace=True)\n\nroute_stats = train_merged.groupby(\"route_id\")[\"final_seatcount\"].agg([\"mean\", \"count\", \"median\"]).reset_index()\nroute_stats.columns = [\"route_id\", \"route_avg_seatcount\", \"route_freq\", \"route_median\"]\ntrain_merged = train_merged.merge(route_stats, on=\"route_id\", how=\"left\")\ntest_merged = test_merged.merge(route_stats, on=\"route_id\", how=\"left\")\n\ntrain_merged[\"search_x_weekend\"] = train_merged[\"search_per_seat\"] * train_merged[\"is_weekend\"]\ntest_merged[\"search_x_weekend\"] = test_merged[\"search_per_seat\"] * test_merged[\"is_weekend\"]\n\ntrain_merged[\"is_month_end\"] = train_merged[\"doj\"].dt.is_month_end.astype(int)\ntest_merged[\"is_month_end\"] = test_merged[\"doj\"].dt.is_month_end.astype(int)\ntrain_merged[\"days_to_weekend\"] = 6 - train_merged[\"doj_dayofweek\"]\ntest_merged[\"days_to_weekend\"] = 6 - test_merged[\"doj_dayofweek\"]\n\ntrain_merged[\"search_to_seat_ratio\"] = train_merged[\"cumsum_searchcount\"] / (train_merged[\"cumsum_seatcount\"] + 1)\ntest_merged[\"search_to_seat_ratio\"] = test_merged[\"cumsum_searchcount\"] / (test_merged[\"cumsum_seatcount\"] + 1)\n\ntrain_merged[\"is_same_region\"] = (train_merged[\"srcid_region\"] == train_merged[\"destid_region\"]).astype(int)\ntest_merged[\"is_same_region\"] = (test_merged[\"srcid_region\"] == test_merged[\"destid_region\"]).astype(int)\n\ncat_cols = [\"srcid_region\", \"destid_region\", \"srcid_tier\", \"destid_tier\"]\nfor col in cat_cols:\n    le = LabelEncoder()\n    train_merged[col] = le.fit_transform(train_merged[col].astype(str))\n    test_merged[col] = le.transform(test_merged[col].astype(str))\n\ntrain_merged[\"route_tier_combo\"] = train_merged[\"srcid_tier\"] * 10 + train_merged[\"destid_tier\"]\ntest_merged[\"route_tier_combo\"] = test_merged[\"srcid_tier\"] * 10 + test_merged[\"destid_tier\"]\n\nroute_freq_rank = train_merged.groupby(\"route_id\")[\"final_seatcount\"].count().rank(method=\"min\", ascending=False).to_dict()\ntrain_merged[\"route_freq_rank\"] = train_merged[\"route_id\"].map(route_freq_rank)\ntest_merged[\"route_freq_rank\"] = test_merged[\"route_id\"].map(route_freq_rank)\n\nskew_feature = (\n    train_merged.groupby([\"route_id\", \"doj_dayofweek\"])[\"final_seatcount\"]\n .skew()\n .reset_index()\n .rename(columns={\"final_seatcount\": \"route_dow_final_seatcount_skew\"})\n)\ntrain_merged = train_merged.merge(skew_feature, on=[\"route_id\", \"doj_dayofweek\"], how=\"left\")\ntest_merged = test_merged.merge(skew_feature, on=[\"route_id\", \"doj_dayofweek\"], how=\"left\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T11:23:15.477331Z","iopub.execute_input":"2025-06-22T11:23:15.477646Z","iopub.status.idle":"2025-06-22T11:23:19.524916Z","shell.execute_reply.started":"2025-06-22T11:23:15.477625Z","shell.execute_reply":"2025-06-22T11:23:19.524150Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# ================== Modeling ==================\ntrain_merged = train_merged.sort_values(\"doj\")\nsplit_idx = int(len(train_merged) * 0.85)\n\nfeatures = [\n    \"doj_dayofweek\", \"doj_month\", \"doj_day\", \"is_weekend\", \"cumsum_seatcount\", \"cumsum_searchcount\",\n    \"search_per_seat\", \"srcid_region\", \"destid_region\", \"srcid_tier\", \"destid_tier\", \"route_id\",\n    \"route_avg_seatcount\", \"route_freq\", \"search_x_weekend\", \"route_median\", \"is_month_end\",\n    \"days_to_weekend\", \"search_to_seat_ratio\", \"route_tier_combo\", \"is_same_region\",\n    \"route_freq_rank\", \"route_dow_final_seatcount_skew\", \"is_holiday\", \"holiday_count\"\n]\n\nX_train = train_merged.iloc[:split_idx][features]\ny_train = train_merged.iloc[:split_idx][\"final_seatcount\"]\nX_val = train_merged.iloc[split_idx:][features]\ny_val = train_merged.iloc[split_idx:][\"final_seatcount\"]\nX_test = test_merged[features]\n\nparams_lgb = {\n    \"objective\": \"regression\", \"metric\": \"rmse\", \"verbosity\": -1,\n    \"boosting_type\": \"gbdt\", \"learning_rate\": 0.03,\n    \"num_leaves\": 50, \"feature_fraction\": 0.9,\n    \"bagging_fraction\": 0.8, \"bagging_freq\": 5, \"seed\": 42\n}\nparams_xgb = {\n    \"objective\": \"reg:squarederror\", \"eval_metric\": \"rmse\",\n    \"learning_rate\": 0.03, \"max_depth\": 7,\n    \"subsample\": 0.8, \"colsample_bytree\": 0.9, \"seed\": 42\n}\n\nlgb_train = lgb.Dataset(X_train, y_train)\nlgb_val = lgb.Dataset(X_val, y_val)\nmodel_lgb = lgb.train(params_lgb, lgb_train, num_boost_round=2000, valid_sets=[lgb_val], callbacks=[lgb.early_stopping(50)])\npreds_lgb_val = model_lgb.predict(X_val)\npreds_lgb_test = model_lgb.predict(X_test)\n\nmodel_xgb = xgb.XGBRegressor(**params_xgb, n_estimators=2000)\nmodel_xgb.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=50, verbose=False)\npreds_xgb_val = model_xgb.predict(X_val)\npreds_xgb_test = model_xgb.predict(X_test)\n\nstk_train = pd.DataFrame({\"lgb\": preds_lgb_val, \"xgb\": preds_xgb_val})\nstk_test = pd.DataFrame({\"lgb\": preds_lgb_test, \"xgb\": preds_xgb_test})\nmeta = Ridge(alpha=1.0)\nmeta.fit(stk_train, y_val)\nmeta_val_preds = meta.predict(stk_train)\nmeta_test_preds = meta.predict(stk_test)\n\nval_rmse = mean_squared_error(y_val, meta_val_preds, squared=False)\nprint(\"Validation RMSE (Blended):\", val_rmse)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T11:23:29.175470Z","iopub.execute_input":"2025-06-22T11:23:29.175781Z","iopub.status.idle":"2025-06-22T11:23:37.724130Z","shell.execute_reply.started":"2025-06-22T11:23:29.175758Z","shell.execute_reply":"2025-06-22T11:23:37.723274Z"}},"outputs":[{"name":"stdout","text":"Training until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[416]\tvalid_0's rmse: 632.864\nValidation RMSE (Blended): 558.2507153263341\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# ================== Save Submission ==================\nsubmission = test[[\"route_key\"]].copy()\nsubmission[\"final_seatcount\"] = np.round(np.clip(meta_test_preds, 0, None)).astype(int)\nsubmission.to_csv(\"submission_with_holidays.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T11:23:58.260657Z","iopub.execute_input":"2025-06-22T11:23:58.260962Z","iopub.status.idle":"2025-06-22T11:23:58.286159Z","shell.execute_reply.started":"2025-06-22T11:23:58.260939Z","shell.execute_reply":"2025-06-22T11:23:58.285274Z"}},"outputs":[],"execution_count":15}]}